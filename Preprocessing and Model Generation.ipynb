{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dafd883-3962-40bc-8054-12fb1ed61402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score,accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1657f4-2c7c-4396-b500-b123ef2b32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data.db')\n",
    "train_data = pd.read_sql('SELECT * FROM train_data', conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc79b7d-88e7-45d5-aaab-ad05aa639f0f",
   "metadata": {},
   "source": [
    "#### \"Predict if the match will end in a draw.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44e0292-d99d-4cb7-9e78-53bfd5c34347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['team2'] != 'ICC World XI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e19551-d27b-489b-89a7-816033cef922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_draw'] = train_data['outcome'].apply(lambda x: 1 if x.lower() == 'draw' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931d370e-eb11-4a8f-98fc-0e9f713f0fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8748\\1815126113.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data.replace(encode, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "encode = {'team1': {'Australia':1,'New Zealand':2,'West Indies':3,'Zimbabwe':4,'Bangladesh':5,'India':6,'England':7,'South Africa':8,'Pakistan':9,'Sri Lanka':10,'Ireland':11},\n",
    "          'team2': {'Australia':1,'New Zealand':2,'West Indies':3,'Zimbabwe':4,'Bangladesh':5,'India':6,'England':7,'South Africa':8,'Pakistan':9,'Sri Lanka':10,'Ireland':11},\n",
    "          'toss_winner': {'Australia':1,'New Zealand':2,'West Indies':3,'Zimbabwe':4,'Bangladesh':5,'India':6,'England':7,'South Africa':8,'Pakistan':9,'Sri Lanka':10,'Ireland':11},\n",
    "          'winner': {'Australia':1,'New Zealand':2,'West Indies':3,'Zimbabwe':4,'Bangladesh':5,'India':6,'England':7,'South Africa':8,'Pakistan':9,'Sri Lanka':10,'Ireland':11}}\n",
    "train_data.replace(encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49fa7a8-55c9-4c78-858d-f422dc09999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['venue', 'toss_decision']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e419ad2-95b1-4fe0-a7f0-862a96f13665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train_data.drop(columns=['match_id','outcome','is_draw','winner','season'])\n",
    "y1 = train_data['is_draw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac367ef8-c687-4dd0-9fd2-0491d93806a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_draw_train, X_draw_test, y_draw_train, y_draw_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28199d99-8418-4f00-b9bb-32f98d765a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {'Logistic Regression': {\"model\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "        \"params\": {\"penalty\": ['elasticnet', 'l1', 'l2'],\"l1_ratio\": [0.0, 0.5, 1.0],}},\n",
    "\n",
    "    'Decision Tree': {\"model\": tree.DecisionTreeClassifier(),\n",
    "        \"params\": {\"criterion\": ['gini', 'entropy'],\"max_depth\": [1, 3, 5, 10, 15, 20, 30],\"min_samples_split\": [2, 5, 10],\"min_samples_leaf\": [1, 2, 4]}},\n",
    "\n",
    "    'Random Forest': {\"model\": RandomForestClassifier(),\n",
    "        \"params\": {\"n_estimators\": [100, 200, 300],\"max_features\": [\"sqrt\", \"log2\", None],\"max_depth\": [5, 10, 20, 30],\"min_samples_split\": [2, 5, 10]}},\n",
    "\n",
    "    'NaiveBayes': {\"model\": GaussianNB(),\"params\": {}},\n",
    "\n",
    "    'K-Nearest Neighbors': {\"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": [3, 5, 10],\"weights\": [\"uniform\", \"distance\"],\"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]}},\n",
    "\n",
    "    'Gradient Boost': {\"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\"learning_rate\": np.arange(0.1, 1, 0.1),\"n_estimators\": [100, 200, 300],\"criterion\": ['friedman_mse', 'squared_error'],\n",
    "            \"min_samples_split\": [2, 5, 10],\"min_samples_leaf\": [1, 2, 4],\"max_depth\": [3, 5, 10, 20],\"max_features\": [\"sqrt\", \"log2\", None]}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54c10a9-8cbc-4211-b881-47c05adb0c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 9 is smaller than n_iter=15. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Draw): Best Score = 0.8051\n",
      "Decision Tree (Draw): Best Score = 0.7991\n",
      "Random Forest (Draw): Best Score = 0.8021\n",
      "NaiveBayes (Draw): Best Score = 0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=15. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (Draw): Best Score = 0.8036\n",
      "Gradient Boost (Draw): Best Score = 0.7872\n"
     ]
    }
   ],
   "source": [
    "draw_prediction_models = {}\n",
    "draw_model_details = []\n",
    "\n",
    "for model_name, values in algorithms.items():\n",
    "    best_score = float('-inf')\n",
    "    best_rscv = None\n",
    "\n",
    "    try:\n",
    "        rscv = RandomizedSearchCV(estimator=values[\"model\"],param_distributions=values[\"params\"],cv=5,n_iter=15,n_jobs=-1,verbose=0,random_state=42)\n",
    "        rscv.fit(X_draw_train, y_draw_train)\n",
    "\n",
    "        if rscv.best_score_ > best_score:\n",
    "            best_score = rscv.best_score_\n",
    "            best_rscv = rscv\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name} (Draw Prediction): {e}\")\n",
    "        continue\n",
    "\n",
    "    if best_rscv:\n",
    "        draw_prediction_models[model_name] = best_rscv\n",
    "        draw_model_details.append({\"Model Name\": model_name,\"Best Score\": best_score,\"Best Parameters\": best_rscv.best_params_})\n",
    "        print(f\"{model_name} (Draw): Best Score = {best_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} (Draw): No valid configuration found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f724afa-6ac5-4a43-a4a0-7259ae45154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>{'penalty': 'elasticnet', 'l1_ratio': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.799071</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 3, 'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.802067</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 10, 'metric': 'minkowski'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.787164</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1, 'criterion': 'squared_error'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Best Score  \\\n",
       "0  Logistic Regression    0.805064   \n",
       "1        Decision Tree    0.799071   \n",
       "2        Random Forest    0.802067   \n",
       "3           NaiveBayes    0.805064   \n",
       "4  K-Nearest Neighbors    0.803571   \n",
       "5       Gradient Boost    0.787164   \n",
       "\n",
       "                                                                                                                                                    Best Parameters  \n",
       "0                                                                                                                        {'penalty': 'elasticnet', 'l1_ratio': 0.0}  \n",
       "1                                                                           {'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 3, 'criterion': 'entropy'}  \n",
       "2                                                                             {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 5}  \n",
       "3                                                                                                                                                                {}  \n",
       "4                                                                                                  {'weights': 'uniform', 'n_neighbors': 10, 'metric': 'minkowski'}  \n",
       "5  {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1, 'criterion': 'squared_error'}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(draw_model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81dd40de-d670-4e99-82a9-a2398d59a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_test_results = []\n",
    "\n",
    "for model_name, model in draw_prediction_models.items():\n",
    "    y_pred = model.predict(X_draw_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_draw_test)[:, 1]\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_draw_test, y_proba)\n",
    "        except:\n",
    "            roc_auc = None\n",
    "    else:\n",
    "        roc_auc = None\n",
    "\n",
    "    report = classification_report(y_draw_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    draw_test_results.append({\"Model Name\": model_name,\"Test Score\": model.score(X_draw_test, y_draw_test),\"Precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report[\"weighted avg\"][\"recall\"],\"F1-score\": report[\"weighted avg\"][\"f1-score\"],\"ROC AUC\": roc_auc})\n",
    "\n",
    "draw_results_df = pd.DataFrame(draw_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "270c37d3-90ad-41e0-8675-60917cc59fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.657155</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.725877</td>\n",
       "      <td>0.425411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.655317</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.719986</td>\n",
       "      <td>0.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.655317</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.719986</td>\n",
       "      <td>0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.657155</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.725877</td>\n",
       "      <td>0.411953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.850416</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.739733</td>\n",
       "      <td>0.559535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.705684</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.729905</td>\n",
       "      <td>0.532162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Test Score  Precision    Recall  F1-score   ROC AUC\n",
       "0  Logistic Regression    0.810651   0.657155  0.810651  0.725877  0.425411\n",
       "1        Decision Tree    0.798817   0.655317  0.798817  0.719986  0.421761\n",
       "2        Random Forest    0.798817   0.655317  0.798817  0.719986  0.511405\n",
       "3           NaiveBayes    0.810651   0.657155  0.810651  0.725877  0.411953\n",
       "4  K-Nearest Neighbors    0.816568   0.850416  0.816568  0.739733  0.559535\n",
       "5       Gradient Boost    0.798817   0.705684  0.798817  0.729905  0.532162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d3412-e1c0-4b09-85e9-fbee4bad2dd0",
   "metadata": {},
   "source": [
    "#### \"If the game produces a result, who has the upper hand?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73cfd36e-ae66-4511-a819-f11980ebbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_train_data = train_data[train_data['is_draw'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54191dbc-7abf-472c-a633-f996f97b33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = winner_train_data.drop(columns=['match_id','outcome','is_draw','winner','season'])\n",
    "y2 = winner_train_data['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c56022c-24ca-4996-be83-71509c8b0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_winner_train, X_winner_test, y_winner_train, y_winner_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c44d6a-edb2-48ee-97d5-c264a31f2bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 9 is smaller than n_iter=15. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Winner): Best Score = 0.3119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (Winner): Best Score = 0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Winner): Best Score = 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=15. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes (Winner): Best Score = 0.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (Winner): Best Score = 0.4871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost (Winner): Best Score = 0.6292\n"
     ]
    }
   ],
   "source": [
    "winner_prediction_models = {}\n",
    "winner_model_details = []\n",
    "\n",
    "for model_name, values in algorithms.items():\n",
    "    best_score = float('-inf')\n",
    "    best_rscv = None\n",
    "\n",
    "    try:\n",
    "        rscv = RandomizedSearchCV(estimator=values[\"model\"],param_distributions=values[\"params\"],cv=5,n_iter=15,n_jobs=-1,verbose=0,random_state=42)\n",
    "        rscv.fit(X_winner_train, y_winner_train)\n",
    "\n",
    "        if rscv.best_score_ > best_score:\n",
    "            best_score = rscv.best_score_\n",
    "            best_rscv = rscv\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name} (Winner Prediction): {e}\")\n",
    "        continue\n",
    "\n",
    "    if best_rscv:\n",
    "        winner_prediction_models[model_name] = best_rscv\n",
    "        winner_model_details.append({\"Model Name\": model_name,\"Best Score\": best_score,\"Best Parameters\": best_rscv.best_params_})\n",
    "        print(f\"{model_name} (Winner): Best Score = {best_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} (Winner): No valid configuration found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0cf4ee-c739-43f2-a983-462def418477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.311859</td>\n",
       "      <td>{'penalty': 'l1', 'l1_ratio': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 15, 'criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.634676</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 10, 'max_features': None, 'max_depth': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.339602</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.487054</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 10, 'metric': 'manhattan'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.629154</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1, 'criterion': 'squared_error'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Best Score  \\\n",
       "0  Logistic Regression    0.311859   \n",
       "1        Decision Tree    0.588515   \n",
       "2        Random Forest    0.634676   \n",
       "3           NaiveBayes    0.339602   \n",
       "4  K-Nearest Neighbors    0.487054   \n",
       "5       Gradient Boost    0.629154   \n",
       "\n",
       "                                                                                                                                                    Best Parameters  \n",
       "0                                                                                                                                {'penalty': 'l1', 'l1_ratio': 0.0}  \n",
       "1                                                                            {'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 15, 'criterion': 'gini'}  \n",
       "2                                                                             {'n_estimators': 200, 'min_samples_split': 10, 'max_features': None, 'max_depth': 20}  \n",
       "3                                                                                                                                                                {}  \n",
       "4                                                                                                 {'weights': 'distance', 'n_neighbors': 10, 'metric': 'manhattan'}  \n",
       "5  {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.1, 'criterion': 'squared_error'}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(winner_model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "756a58b2-48cd-48bf-abc3-4b9c710dabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_test_results = []\n",
    "\n",
    "for model_name, model in winner_prediction_models.items():\n",
    "    y_pred = model.predict(X_winner_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_winner_test)\n",
    "        y_true_bin = label_binarize(y_winner_test, classes=np.unique(y_winner_test))\n",
    "\n",
    "    report = classification_report(y_winner_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    winner_test_results.append({\"Model Name\": model_name,\"Test Score\": model.score(X_winner_test, y_winner_test),\"Precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report[\"weighted avg\"][\"recall\"],\"F1-score\": report[\"weighted avg\"][\"f1-score\"]})\n",
    "\n",
    "winner_results_df = pd.DataFrame(winner_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8c0447-e844-46c1-a3cd-e13e11d3eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.194086</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.219546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.644874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.698698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.363500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.525959</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.518713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.713235</td>\n",
       "      <td>0.716069</td>\n",
       "      <td>0.713235</td>\n",
       "      <td>0.706826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Test Score  Precision    Recall  F1-score\n",
       "0  Logistic Regression    0.264706   0.194086  0.264706  0.219546\n",
       "1        Decision Tree    0.654412   0.675100  0.654412  0.644874\n",
       "2        Random Forest    0.705882   0.724891  0.705882  0.698698\n",
       "3           NaiveBayes    0.382353   0.373056  0.382353  0.363500\n",
       "4  K-Nearest Neighbors    0.544118   0.525959  0.544118  0.518713\n",
       "5       Gradient Boost    0.713235   0.716069  0.713235  0.706826"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea0d77-0b95-4753-a118-136ea394eeb3",
   "metadata": {},
   "source": [
    "#### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "384757db-3aec-4637-ba7f-a770dc153e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['winner_prediction.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(draw_prediction_models[\"K-Nearest Neighbors\"], \"draw_prediction.pkl\")\n",
    "joblib.dump(winner_prediction_models[\"Gradient Boost\"], \"winner_prediction.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f05e9d-dd39-4323-a3db-a04f559c0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c794c-d7b3-4f56-8ba2-d84742689680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
